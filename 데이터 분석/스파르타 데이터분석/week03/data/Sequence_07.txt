자 이번에는 항상 제일

재밌어 하시는 웹스크래핑을 해 볼 예정입니다

그래서 같이 한번 해 볼게요

어떤 거를 우리가 스크래핑 해 올거냐면요

요 겁니다

[코드스니펫] 8번을 한번 복사해서 붙여 넣어 주세요

여기서 우리가 제목만 쭈-욱 긁어올 거예요

그리고 여러분들이 순위 하고 평점까지 긁어오실 겁니다 

같이 한번 해 보겠습니다

이미 여러분들은 이해도가 있으시지만 

이 html은 우리가 막 바꿀 수가 있죠

왜? 우리 거니까 그죠

그래서 이 데이터들을 가지고 오는 데 있어서

딱 두 가지만 하면 돼요

첫 번째는 이렇게 엔터를 쳐 가지고

뭔가 html을 받아오는 작업 

요거는 Requests를 쓰면 금방 해결될 수 있습니다

두 번째, 받아온 html을 잘 솎아내는 방법

내가 원하는 정보를 딱 잘 솎아내야 되잖아요

그래서 첫 번째는 Requests로 해결하고요

두 번째, 잘 솎아내는거는 BeautifulSoup이라는

아주 아름다운 라이브러리가 있습니다

그 라이브러리를 사용해 볼게요

자 똑같이 File > Settings 가셔서 + 누르시고

BeautifulSoup4인데요 줄여서 bs4입니다

그래서 여기 써있죠? BeautifulSoup4를 이렇게

Install Package 해 주십시오

조금만 기다려 주시면 한 10초, 20초 벌써 됐네요

요렇게 됩니다

OK 누르시고 자 이 BeautifulSoup도 

기본 세팅 하는 코드가 있습니다

근데 이 기본 세팅하는 코드들 있잖아요

이거 다 어디 있냐

이거는 라이브러리

이제 그 공식 홈페이지 같은 것들에 가면 

예제 코드로 다 존재를 해요

그래서 우리 이 9번 그대로 복사하셔 가지고

여기에 붙여 넣어 보세요

그 다음에 일단 아무것도 몰라도 괜찮습니다

print(soup)

그다음에 실행(Run)하면 뭔가가 쭉 나옵니다 

딱! 보면 알겠지만

어 이거 html 같은데 느낌이 오시죠

여기서 이제 내가 원하는 정보를

어떻게 솎아내는가가 BeautifulSoup을 이용하는 방법입니다

그래서 제가 코드를 조금씩 한번 설명을 

간단하게만이라도 해드리고 넘어 가 볼게요

첫 번째, requests 가져와라

두 번째, BeautifulSoup 가지고 와라

 가지고 오는 게 뭐는 import고 뭐는 from이 있고 좀 다르네요

이것도 마찬가지로 라이브러리 페이지에 가면 거기

우리는 어떻게 import해서 쓰세요 라고 써져 있습니다

거기서 써 있는 대로

import를 해오시는 게 마음도 편하고 몸도 편합니다. 

두 번째, headers는 일단 넘어갈게요

세 번째, requests.get 아까 하셨죠?

근데 여기 headers가 들어가네요

뭐냐면 이게 사실은 우리가 이렇게 엔터를 치는 것과

그다음에 이 코드가 API 콜을 할 때

headers에서 조금 차이가 있습니다

그거를 마치 우리가 엔터 친 것과 비슷하게 만들어 주려고

headers 값을 강제로 만들어서 넣어 주는 거예요

그 다음에 맨 밑에 거는 BeautifulSoup이라는

라이브러리 형태로 쓸 수 있게 만들어 줘라 라는 겁니다

이 BeautifulSoup은 딱 하나만 기억하시면 돼요 select

select_1이 있고 그냥 select가 있습니다

그냥 select는 당연히 여러 개 가지고 오는 거겠죠

select_1부터 한번 보여 드릴게요

'그린 북'의 검사 누르시고요



그린 북에 가셔서 오른쪽 클릭 > Copy > Copy selector

자 이 상태에서 뭐 할 거냐면

title이라는 변수에 soup 안에서 뭔가를 찾을건데 

soup이 뭐였습니까 이만큼이었죠

soup 안에서 뭔가를 찾을건데

select_one 해놓고 붙여넣기 하면 됩니다

print(title)

그러면 우리가 원하는 부분만 이렇게 솎아주고 있습니다

그래서 만약에 우리가 그린 북을 

그대로 가지고 올 거다 그러면 .text 하면은

요 안에 있는 텍스트만 가지고 와요

만약에 우리가 속성값이라고 하거든요 

이 속성값을 바꾸고 싶다

그러면 이렇게 해 줍니다

.text가 아니고

['href']해서 이렇게

어! 튜터님!

[ ]는 딕셔너리 할 때 쓰는 거 아닌가요?

네~ 맞습니다!

그러나 BeautifulSoup 라이브러리를 사용하는 방법에 대해서

우리가 배우고 있는 거예요

그래서 저도 이 기계가 어떻게 구성됐는지는 몰라요

근데 이렇게 쓰라고 문서에 나와 있습니다

보통 라이브러리들은 각자만의 쓰는 방법들이 있어요

그래서 그거에 맞춰서 그냥 쓰면 돼요

그래서 우리도 이렇게 됩니다 그린 북 이렇게

자 select하면 뭐가 나오냐면요 그냥 보기만 할게요

select 하면 마찬가지로 print(title) 로 했습니다

그러면 이게 보시면 리스트 형태로 나와요

그래서 이거는 여러 개를 가지고 올 때 쓰는 거죠

이 조건에 해당하는 여러 개를 갖고 올 때 쓰는 겁니다

조금 있다 바로 쓸게요 어떻게 할 거냐면

우리가 이제 뭐 할 거냐면

이 타이틀들을 쭉 가지고 올 거예요

근데 이 전략이 중요해요

그래서 보시면 자 이 타이틀을요

이렇게~~~~~ 가지고 오는 것보다

일단 이 한 줄을 가지고 온 다음에 거기서 

순위, 영화명, 평점 이런 식으로 가지고 오는게 훨씬 편하겠죠

그래서 이렇게 tr을 접고 왔다 갔다 해 보시면

아 tr들이 한줄 한줄이구나

고로 tr을 먼저 가지고 오는 게 중요하구나를

아실 수가 있습니다

그래서 오른쪽 클릭 > Copy > Copy selector

이번에는 여기서 싹 지우고 tr들을 가져와 볼게요

trs = soup.select 해서 이렇게 넣으면 되는데

print(trs) 해 보세요

근데 이렇게 하면 하나밖에 안 갖고 와요

너무 당연하게도 왜냐하면 두 번째 tr에 대고

우리가 마우스를 클릭했기 때문이에요

그래서 tr:nth-child(2)만 없애 주고

다시 보면 tr들이 여러개가 돌죠?

tr의 0번째는 이런 게 나오고요

1 번째는 또 이런 게 나옵니다

그래서 이제 for문을 돌려보죠

for tr in trs 해가지고

print(tr) 하면 tr이 하나하나씩 나오겠죠

근데 우리는 하나 하나 안에서 뭘 해야 되냐면

이 타이틀을 이제 꺼내올 거잖아요

그죠 그러면 이렇게 합니다

이렇게 해요 보세요

a_tag 라고 합시다

a_tag = tr.select_one

어떻게 찾아 가냐

a_tag라는 변수에다가 이제 우리가 찾은 a_tag를 넣고

그 안에서 뭐 제목을 가지고 오든지

뭐 이렇게 할 겁니다

어떻게 하냐면 '그린 북'을 이렇게 검사해보세요 

가서 Copy > Copy selector 마찬가지로 합니다

다음에 여기다가 이렇게 가운데다 한번 넣어 보세요

그러면 여기까지는 동일해요 그죠

여기까지는 동일합니다

이 nth-child(2)가 나온 이유는

내가 두 번째 그린 북에다가만 대고 

지금 마우스를 클릭해서 그래요

근데 tr 안에 있는 거는 td 부터 이만큼만 다르죠

다른 것만 넣어 주시면 돼요

tr 안에서 이만큼만 더 찾으면 된다

print(a_tag)

해보시면 쭉 나옵니다 근데 재밌는 게 뭐냐면

None이 중간중간에 섞여 있어요

그래서 이건 저만 해볼게요

제가 만약에 여기서 .text 를 하잖아요

그러면 분명히 얘네들은 잘 되겠죠

그러나 None에서도 .text를 하려고 시도할 것이기 때문에

에러가 난다는 말이죠 여기 써 있잖아요

'Nonetype' object has no attribute 'text'

그래서 여기서 이렇게 줍니다

if a_tag 가 None이 아닐 때

아닐 때 어떻게 쓸까요?

!= 하면 아닐 때 입니다 

근데 파이썬은요 재밌는 게

None에 한해서 is not None을 쓰기를 권장하고 있어요

그래서 우리도 그렇게 해 볼게요

a_tag가 None이 아니면 그럼 뭘 해라?

title = a_tag.text

그래서 print(title) 하면 됐죠

그죠 이렇게 하나가 또 완성이 된 겁니다

이제 여러분들이 조금 해 주셔야 될 게 있는데요

이렇게 순위와 평점을 한번 가져와 보시면 되겠습니다

그래서 제가 바로 퀴즈 설명 한번 해 드릴게요!